{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNM3KJkrOBW+k79dnrIIXa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadJahanzaibTariq/ML/blob/main/DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "3yCoY4vfvFR7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpD7JaNYtt1b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# for data manipulation, analysis and reading our dataset\n",
        "import pandas as pd\n",
        "\n",
        "# for plotting and visualising the data\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dataset"
      ],
      "metadata": {
        "id": "OXz1FA7Yu-sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "X=dataset.iloc[:,:-1].values # X IS A MATRIX\n",
        "y=dataset.iloc[:,-1].values #y IS a vector\n",
        "print(X)"
      ],
      "metadata": {
        "id": "p553ByAkuNru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae49e2ca-9d55-4dca-a896-5603cb68af88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Contains Feature and** dependent_variable vector**\n",
        "Feature**:Feature are independent variable with which you can predict a dependent variable**\n",
        "\n",
        "In Our case Country AGE and Salary in Feature or Independent Variable\n",
        "and Purchased is dependent varibale\n",
        "\n",
        "**WHAT IS OUR GOAL?:**\n",
        "      A company want to find that a future customer will purchase the product or not if age Salary and country is given\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D_C4TOfrvbzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taking Care Of Missing data"
      ],
      "metadata": {
        "id": "bEF_8h-eZ4ZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This article covers 7 ways to handle missing values in the dataset:\n",
        "<br>Deleting Rows with missing values<br>\n",
        "<br>Impute missing values for continuous variable<br>\n",
        "<br>Impute missing values for categorical variable<br>\n",
        "<br>Other Imputation Methods<br>\n",
        "<br>Using Algorithms that support missing values<br>\n",
        "<br>Prediction of missing values<br>\n",
        "<br>Imputation using Deep Learning Library — Datawig<br>\n",
        "\n",
        "https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e"
      ],
      "metadata": {
        "id": "ZVnNB1aWaC7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:,1:3])\n",
        "X[:,1:3]=imputer.transform(X[:,1:3])\n",
        "print(X)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwx5YvE6g1rC",
        "outputId": "b15384fc-886e-4177-f49b-e35b1f747e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding catagorical data"
      ],
      "metadata": {
        "id": "iNqnyRbKl8Yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**Encoding catagorical data**<br>\n",
        "Three type of Encoding(there are more but for now just these three)\n",
        "<br>1)**Nominal Encoding**<br>\n",
        "2)**Ordinal Encoding**\n",
        "\n",
        "\n",
        "\n",
        "<br>1)**Nominal Encoding**:<br>\n",
        "Nominal Encoding\n",
        "When we have a feature where variables are just names and there is no order or rank to this variable's feature.\n",
        "\n",
        "https://miro.medium.com/max/1400/1*cnmpSdK-6hAQJdTUBFxcnA.png\n",
        "\n",
        "For example: City of person lives in, Gender of person, Marital Status, etc…\n",
        "In the above example, We do not have any order or rank, or sequence. All the variables in the respective feature are equal. We can't give them any orders or ranks. Those features are called Nominal features.\n",
        "  -><br>**Nominal Encoding** is further divided into<br>\n",
        "           ----->    1)**One_Hot Encoding**<br>\n",
        "           ----->    2)**One_Hot Encoding with many catagorical**<br>\n",
        "           ----->    3)**Mean Encoding**\n",
        "\n",
        "2)**Ordinal Encoding**\n",
        "\n",
        " When we have a feature where variables have some order/rank.\n",
        "\n",
        " https://miro.medium.com/max/654/1*NUzgzszTdpLPZpeKPPf0kQ.png\n",
        "\n",
        "For example: Student’s performance, Customer’s review, Education of person, etc…\n",
        "\n",
        "**One_Hot Encoding**\n",
        "\n",
        "   In one hot encoding you can just see Nominal encoding\n",
        "\n",
        "   but the thing i am going to discuss is** dummy varible ** trap \n",
        "\n",
        "   suppose we have date like this\n",
        "\n",
        "  Germnay= 100\n",
        "  France=010\n",
        "  Spain=001\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Germany</th>\n",
        "    <th>France</th>\n",
        "    <th>Spain</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>1</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "   <tr>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>1</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "But we can remove one coloumn this is called dummy varible trap\n",
        " Germnay= 10\n",
        "  France=01\n",
        "  Spain=00\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Germany</th>\n",
        "    <th>France</th>\n",
        "    <th>Spain</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>1</td>\n",
        "  </tr>\n",
        "   <tr>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "This will work fine as encoding if we have three make it 3-1=2 nd so on\n"
      ],
      "metadata": {
        "id": "E2PHsRPhmeyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n",
        "X=np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "66dcEzfOmUKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbH0LQvgqCnp",
        "outputId": "74bda9d9-0ff9-44a5-d3ef-a83aa50d3e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb=LabelEncoder()\n",
        "y=lb.fit_transform(y)"
      ],
      "metadata": {
        "id": "UeYNFWIQpcj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ6zVMdSrT4k",
        "outputId": "2db23f57-3713-42d8-a799-76783d5ec8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranning and Test Set"
      ],
      "metadata": {
        "id": "xQUFWXetdgHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "eKFjFrrbdyTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "Mkqv0_aKLwUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/Y7m9MyPxcyQ<br>\n",
        "**Q:**what is Feature Scaling?<br>\n",
        "Ans:Feature Scaling is a technique to standardize the **independent features** present in the data in a fixed range. It is performed during the data pre-processing to handle highly varying magnitudes or values or units<br>\n",
        "Q why We need Feature Scaling?<br>\n",
        "Ans:If feature scaling is not done, then a machine learning algorithm tends to weight greater values, higher and consider smaller values as the lower values, regardless of the unit of the values.<br>\n",
        "**Q:**What are the type of Feature Scaling?<br>\n",
        "\n",
        "**Min-Max Normalization:** This technique re-scales a feature or observation value with distribution value between 0 and 1.\n",
        "\n",
        "<center><img src=\"https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-282fedefcd0fdf4868ad00ca7e161849_l3.svg\" class=\"ql-img-inline-formula quicklatex-auto-format\" alt=\"X_{\\text {new }}=\\frac{X_{i}-\\min (X)}{\\max (x)-\\min (X)}\" title=\"Rendered by QuickLaTeX.com\" height=\"42\" width=\"253\" style=\"vertical-align:-14px\"></center>\n",
        "\n",
        "**Standardization:** It is a very effective technique which re-scales a feature value so that it has distribution with 0 mean value and variance equals to 1.\n",
        "\n",
        "<center><img src=\"https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-98d57b82f228c735de66f69c749a14c7_l3.svg\" class=\"ql-img-inline-formula quicklatex-auto-format\" alt=\"X_{\\text {new }}=\\frac{X_{i}-X_{\\text {mean }}}{\\text { Standard Deviation }}\" title=\"Rendered by QuickLaTeX.com\" height=\"33\" width=\"293\" style=\"vertical-align:-9px\"></center>\n",
        "\n",
        "Xi=Current value of the **list**\n",
        "Xmean is also written as μ  MU  As we know Mean is average of all value so Xmean mean Average of all value in List\n",
        "\n"
      ],
      "metadata": {
        "id": "MukVv9NOMap6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNck65fqd8Az",
        "outputId": "cb555b30-3f06-4296-8dc6-5bcc0d748245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 0.2630675731713538 0.1238147854838185]\n",
            " [1.0 0.0 0.0 -0.25350147960148617 0.4617563176278856]\n",
            " [0.0 0.0 1.0 -1.9753983221776195 -1.5309334063940294]\n",
            " [0.0 0.0 1.0 0.05261351463427101 -1.1114197802841526]\n",
            " [1.0 0.0 0.0 1.6405850472322605 1.7202971959575162]\n",
            " [0.0 0.0 1.0 -0.08131179534387283 -0.16751412153692966]\n",
            " [1.0 0.0 0.0 0.9518263102018072 0.9861483502652316]\n",
            " [1.0 0.0 0.0 -0.5978808481167128 -0.48214934111933727]]\n",
            "[[0.0 1.0 0.0 -1.4588292694047795 -0.9016629672292141]\n",
            " [0.0 1.0 0.0 1.984964415747487 2.139810822067393]]\n"
          ]
        }
      ]
    }
  ]
}